{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperpearameter Database Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "Hyperparameters are the parameters of an algorithm that has to be defined before running the models. If the ideal values of those parameters are defined then it can greatly improve the models predictibility. \n",
    "It is difficult to get the values manually. So in this project we are using H2O software to get the ideal values of the hyperparameters so that it can give the best result about the algorithm.\n",
    "In this project I have ran H2O on the mushroom classification dataset for 5 runtimes. I have got a leaderboard for each and every runtime. Then exported the hyperparameter values of each model to json files.\n",
    "In this project I have tried to find the important hyperparameters for every model, found the ranges of those hyperparameters and compared those across the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import random, os, sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import csv\n",
    "import optparse\n",
    "import time\n",
    "import json\n",
    "from distutils.util import strtobool\n",
    "import psutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection  import train_test_split \n",
    "from sklearn.metrics import accuracy_score, log_loss, mean_squared_error\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to H2O cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode)\n",
      "  Starting server from C:\\Users\\deodh\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: c:\\users\\deodh\\appdata\\local\\temp\\tmprofzry\n",
      "  JVM stdout: c:\\users\\deodh\\appdata\\local\\temp\\tmprofzry\\h2o_deodh_started_from_python.out\n",
      "  JVM stderr: c:\\users\\deodh\\appdata\\local\\temp\\tmprofzry\\h2o_deodh_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>19 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_deodh_6k182v</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.535 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>AutoML, Amazon S3, Algos, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.16 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O cluster uptime:         04 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.1\n",
       "H2O cluster version age:    19 days\n",
       "H2O cluster name:           H2O_from_python_deodh_6k182v\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.535 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         AutoML, Amazon S3, Algos, Core V3, Core V4\n",
       "Python version:             2.7.16 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "port_no = 54321\n",
    "h2o.init(strict_version_check=False) # start h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"mushrooms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing the data frame to H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df = h2o.H2OFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for RunId\n",
    "Here we have created a run function for each runtime where we can select how many characters we want for the runid. This function creates a random runid everytime we execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_id(n):\n",
    "    letter='0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'    \n",
    "    str=''\n",
    "    r=len(letter)-1   \n",
    "    while len(str)<n:\n",
    "        i=random.randint(0,r)\n",
    "        str+=letter[i]   \n",
    "    return str\n",
    "server_path=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path= 'C:\\Users\\deodh\\Desktop\\hyperparameter\\mushrooms.csv'\n",
    "all_variables=None\n",
    "test_path=None\n",
    "target=None\n",
    "nthreads=1 \n",
    "min_mem_size=6 \n",
    "run_time=400\n",
    "classification=True\n",
    "scale=False\n",
    "max_models=100   \n",
    "model_path=None\n",
    "balance_y=False \n",
    "balance_threshold=0.2\n",
    "name=None \n",
    "server_path=None  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definig the metadata values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def meta_data(run_id,server,data,test,model_path,target,run_time,regression,model,balance,balance_threshold,name,path,nthreads,min_mem_size):\n",
    "    m_data={}\n",
    "    m_data['start_time'] = time.time()\n",
    "    m_data['target']=target\n",
    "    m_data['server_path']=server\n",
    "    m_data['data_path']=data \n",
    "    m_data['test_path']=test\n",
    "    m_data['max_models']=model\n",
    "    m_data['run_time']=run_time\n",
    "    m_data['run_id'] =run_id\n",
    "    m_data['scale']=scale\n",
    "    m_data['classification']=classification\n",
    "    m_data['scale']=False\n",
    "    m_data['model_path']=model_path\n",
    "    m_data['balance']=balance\n",
    "    m_data['balance_threshold']=balance_threshold\n",
    "    m_data['project'] =name\n",
    "    m_data['end_time'] = time.time()\n",
    "    m_data['execution_time'] = 0.0\n",
    "    m_data['run_path'] =path\n",
    "    m_data['nthreads'] = nthreads\n",
    "    m_data['min_mem_size'] = min_mem_size\n",
    "    return m_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target and Independent varaibles\n",
    "Here we define the target and varibles as X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'veil-color', u'cap-surface', u'habitat', u'odor', u'stalk-root', u'cap-shape', u'cap-color', u'stalk-color-above-ring', u'spore-print-color', u'gill-color', u'population', u'stalk-color-below-ring', u'ring-type', u'stalk-shape', u'bruises', u'stalk-surface-above-ring', u'veil-type', u'gill-attachment', u'gill-spacing', u'ring-number', u'stalk-surface-below-ring', u'gill-size']\n",
      "class\n"
     ]
    }
   ],
   "source": [
    "target = 'class'\n",
    "\n",
    "def get_independent_variables(train_data, targ):\n",
    "    C = [name for name in train_data.columns if name != targ]\n",
    "    # determine column types\n",
    "    ints, reals, enums = [], [], []\n",
    "    for key, val in train_data.types.items():\n",
    "        if key in C:\n",
    "            if val == 'enum':\n",
    "                enums.append(key)\n",
    "            elif val == 'int':\n",
    "                ints.append(key)            \n",
    "            else: \n",
    "                reals.append(key)    \n",
    "    x = ints + enums + reals\n",
    "    return x\n",
    "\n",
    "X = get_independent_variables(df, target) \n",
    "print(X)\n",
    "y = target\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the runtime for H2O to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " run_time=400\n",
    "aml1 = H2OAutoML(max_runtime_secs=run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_start_time = time.time()\n",
    "aml1.train(x=X,y=y,training_frame=df)  # Change training_frame=train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a run_id\n",
    "Here we use the run_id function where we can define the number of characters. We have set the path to create a folder for run_id to the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Rr6eu3vHP\n"
     ]
    }
   ],
   "source": [
    "\n",
    "runid=run_id(10)\n",
    "if server_path==None:\n",
    "    server_path=os.path.abspath(os.curdir)\n",
    "os.chdir(server_path) \n",
    "run_dir = os.path.join(server_path,runid)\n",
    "os.mkdir(run_dir)\n",
    "os.chdir(run_dir)    \n",
    "\n",
    "print (runid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing the leaderboard generated by H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">    logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">       rmse</th><th style=\"text-align: right;\">        mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_1_AutoML_20190420_034740_model_6          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.384723   </td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.319508   </td><td style=\"text-align: right;\">0.102086   </td></tr>\n",
       "<tr><td>GBM_2_AutoML_20190420_034740                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">9.88049e-18</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">5.43808e-16</td><td style=\"text-align: right;\">2.95727e-31</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190420_034740_model_4          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00223732 </td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.00480168 </td><td style=\"text-align: right;\">2.30561e-05</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190420_034740                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">1.1463e-16 </td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">7.13105e-15</td><td style=\"text-align: right;\">5.08518e-29</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20190420_034740                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">8.63689e-18</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">7.17082e-16</td><td style=\"text-align: right;\">5.14206e-31</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190420_034740   </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.000885639</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.000908697</td><td style=\"text-align: right;\">8.25731e-07</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190420_034740_model_1          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">4.86686e-16</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">4.02041e-14</td><td style=\"text-align: right;\">1.61637e-27</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190420_034740                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">3.64471e-17</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">2.38155e-15</td><td style=\"text-align: right;\">5.6718e-30 </td></tr>\n",
       "<tr><td>GLM_grid_1_AutoML_20190420_034740_model_1          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00199809 </td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.00783831 </td><td style=\"text-align: right;\">6.1439e-05 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190420_034740</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00150672 </td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.001699   </td><td style=\"text-align: right;\">2.88662e-06</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190420_034740_model_5          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.028273   </td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0301144  </td><td style=\"text-align: right;\">0.000906879</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190420_034740_model_2          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">2.18655e-18</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">9.94906e-17</td><td style=\"text-align: right;\">9.89839e-33</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190420_034740_model_3          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">2.15922e-18</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">5.02461e-17</td><td style=\"text-align: right;\">2.52467e-33</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20190420_034740                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.000792769</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0078452  </td><td style=\"text-align: right;\">6.15471e-05</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20190420_034740                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">7.89376e-14</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">8.91524e-13</td><td style=\"text-align: right;\">7.94814e-25</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20190420_034740              </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.000980243</td><td style=\"text-align: right;\">           0.000118821</td><td style=\"text-align: right;\">0.0143783  </td><td style=\"text-align: right;\">0.000206734</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190420_034740_model_1 </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00448139 </td><td style=\"text-align: right;\">           0.000127681</td><td style=\"text-align: right;\">0.0323614  </td><td style=\"text-align: right;\">0.00104726 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190420_034740_model_2 </td><td style=\"text-align: right;\">0.999907</td><td style=\"text-align: right;\">0.0163954  </td><td style=\"text-align: right;\">           0.00334108 </td><td style=\"text-align: right;\">0.0673431  </td><td style=\"text-align: right;\">0.0045351  </td></tr>\n",
       "<tr><td>XRT_1_AutoML_20190420_034740                       </td><td style=\"text-align: right;\">0.998576</td><td style=\"text-align: right;\">0.142902   </td><td style=\"text-align: right;\">           0.00803191 </td><td style=\"text-align: right;\">0.171061   </td><td style=\"text-align: right;\">0.0292619  </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190420_034740_model_7          </td><td style=\"text-align: right;\">0.914012</td><td style=\"text-align: right;\">0.687645   </td><td style=\"text-align: right;\">           0.105848   </td><td style=\"text-align: right;\">0.497244   </td><td style=\"text-align: right;\">0.247252   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb1 = aml1.leaderboard\n",
    "lb1.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             GBM_grid_1_AutoML_20190420_034740_model_6\n",
       "1                          GBM_2_AutoML_20190420_034740\n",
       "2             GBM_grid_1_AutoML_20190420_034740_model_4\n",
       "3                          GBM_4_AutoML_20190420_034740\n",
       "4                          GBM_1_AutoML_20190420_034740\n",
       "5      StackedEnsemble_AllModels_AutoML_20190420_034740\n",
       "6             GBM_grid_1_AutoML_20190420_034740_model_1\n",
       "7                          GBM_3_AutoML_20190420_034740\n",
       "8             GLM_grid_1_AutoML_20190420_034740_model_1\n",
       "9     StackedEnsemble_BestOfFamily_AutoML_20190420_0...\n",
       "10            GBM_grid_1_AutoML_20190420_034740_model_5\n",
       "11            GBM_grid_1_AutoML_20190420_034740_model_2\n",
       "12            GBM_grid_1_AutoML_20190420_034740_model_3\n",
       "13                         DRF_1_AutoML_20190420_034740\n",
       "14                         GBM_5_AutoML_20190420_034740\n",
       "15                DeepLearning_1_AutoML_20190420_034740\n",
       "16    DeepLearning_grid_1_AutoML_20190420_034740_mod...\n",
       "17    DeepLearning_grid_1_AutoML_20190420_034740_mod...\n",
       "18                         XRT_1_AutoML_20190420_034740\n",
       "19            GBM_grid_1_AutoML_20190420_034740_model_7\n",
       "Name: model_id, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml1_leaderboard_df=aml1.leaderboard.as_data_frame()\n",
    "model_set=aml1_leaderboard_df['model_id']\n",
    "model_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the metadata and exporing it to the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': '2Rr6eu3vHP', 'min_mem_size': 6, 'server_path': None, 'scale': False, 'target': 'class', 'classification': True, 'test_path': None, 'execution_time': 0.0, 'start_time': 1555747273.322, 'data_path': 'C:\\\\Users\\\\deodh\\\\Desktop\\\\hyperparameter\\\\mushrooms.csv', 'run_path': 'C:\\\\Users\\\\deodh\\\\Desktop\\\\hyperparameter\\\\2Rr6eu3vHP', 'project': None, 'end_time': 1555747273.322, 'nthreads': 1, 'run_time': 400, 'max_models': 100, 'balance': False, 'balance_threshold': 0.2, 'model_path': None}\n"
     ]
    }
   ],
   "source": [
    "metadata = meta_data(runid,server_path,data_path,test_path,model_path,target,run_time,classification,max_models,balance_y,balance_threshold,name,run_dir,nthreads,min_mem_size)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting metadata, leaderboard and all the hyperparameters to json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = json.dumps(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.json', 'w') as fp:\n",
    "    json.dump(metadata, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = lb1.as_data_frame()\n",
    "df1.to_csv(\"400leaderboard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = h2o.get_model(lb1[0,'model_id'])\n",
    "model1 = model1.params\n",
    "with open('model1-GBM_1.json', 'w') as fp:\n",
    "    json.dump(model1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = h2o.get_model(lb1[1,'model_id'])\n",
    "model2 = model2.params\n",
    "with open('model2-GBM_4.json', 'w') as fp:\n",
    "    json.dump(model2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = h2o.get_model(lb1[2,'model_id'])\n",
    "model3 = model3.params\n",
    "with open('model3-GBM_3.json', 'w') as fp:\n",
    "    json.dump(model3, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = h2o.get_model(lb1[3,'model_id'])\n",
    "model4 = model4.params\n",
    "with open('model4-GBM_grid_1_2.json', 'w') as fp:\n",
    "    json.dump(model4, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = h2o.get_model(lb1[4,'model_id'])\n",
    "model5 = model5.params\n",
    "with open('model5-GLM_grid_1_1.json', 'w') as fp:\n",
    "    json.dump(model5, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = h2o.get_model(lb1[5,'model_id'])\n",
    "model6 = model6.params\n",
    "with open('model6-GLM_grid_1_4.json', 'w') as fp:\n",
    "    json.dump(model6, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = h2o.get_model(lb1[6,'model_id'])\n",
    "model7 = model7.params\n",
    "with open('model7-GBM_5.json', 'w') as fp:\n",
    "    json.dump(model7, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = h2o.get_model(lb1[7,'model_id'])\n",
    "model8 = model8.params\n",
    "with open('model8-GBM_grid_1_3.json', 'w') as fp:\n",
    "    json.dump(model8, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9 = h2o.get_model(lb1[8,'model_id'])\n",
    "model9 = model9.params\n",
    "with open('model9-StackedEnsemble_AllModels.json', 'w') as fp:\n",
    "    json.dump(model9, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = h2o.get_model(lb1[9,'model_id'])\n",
    "model10 = model10.params\n",
    "with open('model10-DeepLearning_1.json', 'w') as fp:\n",
    "    json.dump(model10, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11 = h2o.get_model(lb1[10,'model_id'])\n",
    "model11 = model11.params\n",
    "with open('model11-DRF_1.json', 'w') as fp:\n",
    "    json.dump(model11, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12 = h2o.get_model(lb1[11,'model_id'])\n",
    "model12 = model12.params\n",
    "with open('model12-GBM_2.json', 'w') as fp:\n",
    "    json.dump(model12, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model13 = h2o.get_model(lb1[12,'model_id'])\n",
    "model13 = model13.params\n",
    "with open('model13-GBM_grid_1_1.json', 'w') as fp:\n",
    "    json.dump(model13, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model14 = h2o.get_model(lb1[13,'model_id'])\n",
    "model14 = model14.params\n",
    "with open('model14-StackedEnsemble_BestOfFamily.json', 'w') as fp:\n",
    "    json.dump(model14, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model15 = h2o.get_model(lb1[14,'model_id'])\n",
    "model15 = model15.params\n",
    "with open('model15-DeepLearning_grid_1_2.json', 'w') as fp:\n",
    "    json.dump(model15, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model16 = h2o.get_model(lb1[15,'model_id'])\n",
    "model16 = model16.params\n",
    "with open('model16-GBM_grid_1_5.json', 'w') as fp:\n",
    "    json.dump(model16, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model17 = h2o.get_model(lb1[16,'model_id'])\n",
    "model17 = model17.params\n",
    "with open('model17-DeepLearning_grid_1_1.json', 'w') as fp:\n",
    "    json.dump(model17, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model18 = h2o.get_model(lb1[17,'model_id'])\n",
    "model18 = model18.params\n",
    "with open('model18-XRT_1.json', 'w') as fp:\n",
    "    json.dump(model18, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model19 = h2o.get_model(lb1[18,'model_id'])\n",
    "model19 = model19.params\n",
    "with open('model19-DeepLearning_grid_1_3.json', 'w') as fp:\n",
    "    json.dump(model19, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model20 = h2o.get_model(lb1[19,'model_id'])\n",
    "model20 = model20.params\n",
    "with open('model20.json', 'w') as fp:\n",
    "    json.dump(model20, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project I ran H2O for 5 runtimes 200,400,600,1000 and got the best models which gave the best results. Stored them in the csv and stored their hyperparameters in the json files. I found the ranges of the hyperparameters of each algorithm.\n",
    "GBM algorithm had the most models that got generated.\n",
    "\n",
    "1. For GBM ntrees, learning rate,stopping tolerence are the best hyperparameters.\n",
    "2. For XRT sample rate and stopping tolerence are the best hyperparameters.\n",
    "3. For DRF sample rate, stopping tolerence, seed and ntrees are the best hyperparameters.\n",
    "4. For Deep Learning stopping_tolerence, rate, maxw2, huberalpha, elastic averaging moving rate and averaging regularization are the best hyperparameters.\n",
    "\n",
    "I have compared the hyperparameters of all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution\n",
    "40% by me and \n",
    "60% from external resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation\n",
    "\n",
    "http://docs.h2o.ai/h2o/latest-stable/h2o-docs/grid-search.html\n",
    "\n",
    "https://github.com/prabhuSub/Hyperparamter-Samples/tree/master/Hyperparamet\n",
    "\n",
    "https://github.com/nikbearbrown/CSYE_7245/tree/master/H2O\n",
    "\n",
    "https://www.jeremyjordan.me/hyperparameter-tuning/\n",
    "\n",
    "https://towardsdatascience.com/understanding-hyperparameters-and-its-optimisation-techniques-f0debba07568"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "Copyright 2019 Mayuresh Deodhar\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
